{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import tifffile \n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import skimage \n",
    "import skimage.io\n",
    "import skimage.measure\n",
    "import skimage.morphology\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # specify visible gpu(s) 0-3\n",
    "import tensorflow as tf\n",
    "try:\n",
    "    tf_gpus = tf.config.list_physical_devices('GPU')\n",
    "    for gpu in tf_gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True) # allow memory growth on visible gpu(s)\n",
    "except:\n",
    "    pass \n",
    "\n",
    "import skimage.io as io\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "from deepcell.applications import Mesmer\n",
    "from deepcell.utils.plot_utils import create_rgb_image, make_outline_overlay\n",
    "\n",
    "from INDEPTH_functions import process_fusion_image, segment_image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Fusion scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the 8-bit qptiffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFCI_scan = tifffile.imread('../data/INDEPTH_DLBCL_Right_Scan1.qptiff')\n",
    "\n",
    "Rochester_scan = tifffile.imread('../data/INDEPTH_DLBCL_Left_Scan1.qptiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load core position csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the csv that record the position of each core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFCI_core_position = pd.read_csv('../data/DFCI_core_position.csv')\n",
    "Rochester_core_position = pd.read_csv('../data/Rochester_core_position.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty canvas for putting the cores back after crop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFCI_canvas = np.zeros_like(DFCI_scan[0], 'uint8')\n",
    "Rochester_canvas = np.zeros_like(Rochester_scan[0], 'uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop cores and put them back into the empty canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in DFCI_core_position['Core']:\n",
    "    x1 = DFCI_core_position[DFCI_core_position['Core'] == i]['x1'].values[0]\n",
    "    x2 = DFCI_core_position[DFCI_core_position['Core'] == i]['x2'].values[0]\n",
    "    y1 = DFCI_core_position[DFCI_core_position['Core'] == i]['y1'].values[0]\n",
    "    y2 = DFCI_core_position[DFCI_core_position['Core'] == i]['y2'].values[0]\n",
    "    core_img = DFCI_scan[0][y1:y2, x1:x2]\n",
    "    #tifffile.imshow(core_img)\n",
    "    DFCI_canvas[y1:y2, x1:x2] = core_img\n",
    "\n",
    "\n",
    "for i in Rochester_core_position['Core']:\n",
    "    x1 = Rochester_core_position[Rochester_core_position['Core'] == i]['x1'].values[0]\n",
    "    x2 = Rochester_core_position[Rochester_core_position['Core'] == i]['x2'].values[0]\n",
    "    y1 = Rochester_core_position[Rochester_core_position['Core'] == i]['y1'].values[0]\n",
    "    y2 = Rochester_core_position[Rochester_core_position['Core'] == i]['y2'].values[0]\n",
    "    core_img = Rochester_scan[0][y1:y2, x1:x2]\n",
    "    #tifffile.imshow(core_img)\n",
    "    Rochester_canvas[y1:y2, x1:x2] = core_img\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual check to make sure the coordinates are correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize = (12,12))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.imshow(DFCI_scan[0], cmap='gray')\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.imshow(DFCI_canvas, cmap = 'gray', alpha=1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize = (12,12))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.imshow(Rochester_scan[0], cmap='gray')\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.imshow(Rochester_canvas, cmap = 'gray', alpha=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate Fusion scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since later we will be registering the Fusion scan and the GeoMx scan. We will now rotate the Fusion scan clockwise 180 degrees to have them in the same orientation as the GeoMx scan, in order to eliminate one variable when registering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFCI_rotate_list = []\n",
    "Rochester_rotate_list = []\n",
    "\n",
    "for i in range(DFCI_scan.shape[0]):\n",
    "    print(f'Rotating the {i}th channel')\n",
    "    channel_rotate = cv2.rotate(DFCI_scan[i], cv2.ROTATE_180)\n",
    "    DFCI_rotate_list.append(channel_rotate)\n",
    "\n",
    "DFCI_rotate = np.stack(DFCI_rotate_list)\n",
    "\n",
    "for i in range(Rochester_scan.shape[0]):\n",
    "    print(f'Rotating the {i}th channel')\n",
    "    channel_rotate = cv2.rotate(Rochester_scan[i], cv2.ROTATE_180)\n",
    "    Rochester_rotate_list.append(channel_rotate)\n",
    "\n",
    "Rochester_rotate = np.stack(Rochester_rotate_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,12))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.imshow(DFCI_rotate[0], cmap = 'gray')\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.imshow(Rochester_rotate[0], cmap = 'gray')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate rotated coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFCI_core_position['x1_rotate'] = DFCI_scan.shape[2] - DFCI_core_position['x1'] \n",
    "DFCI_core_position['x2_rotate'] = DFCI_scan.shape[2] - DFCI_core_position['x2'] \n",
    "DFCI_core_position['y1_rotate'] = DFCI_scan.shape[1] - DFCI_core_position['y1'] \n",
    "DFCI_core_position['y2_rotate'] = DFCI_scan.shape[1] - DFCI_core_position['y2'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rochester_core_position['x1_rotate'] = Rochester_scan.shape[2] - Rochester_core_position['x1'] \n",
    "Rochester_core_position['x2_rotate'] = Rochester_scan.shape[2] - Rochester_core_position['x2'] \n",
    "Rochester_core_position['y1_rotate'] = Rochester_scan.shape[1] - Rochester_core_position['y1'] \n",
    "Rochester_core_position['y2_rotate'] = Rochester_scan.shape[1] - Rochester_core_position['y2'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put the cropped cell back into a blank canvas\n",
    "\n",
    "Optional step to check if the cores were all rotated correctly and if the calculated rotated coordinates were correct. The DAPI channel were used for visual checking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFCI_piece_together = np.zeros_like(DFCI_rotate[0], 'uint8')\n",
    "Rochester_piece_together = np.zeros_like(Rochester_rotate[0], 'uint8')\n",
    "\n",
    "for i in DFCI_core_position['Core']:\n",
    "    x1 = DFCI_core_position[DFCI_core_position['Core'] == i]['x2_rotate'].values[0]\n",
    "    x2 = DFCI_core_position[DFCI_core_position['Core'] == i]['x1_rotate'].values[0]\n",
    "    y1 = DFCI_core_position[DFCI_core_position['Core'] == i]['y2_rotate'].values[0]\n",
    "    y2 = DFCI_core_position[DFCI_core_position['Core'] == i]['y1_rotate'].values[0]\n",
    "    core_img = DFCI_rotate[0][y1:y2, x1:x2]\n",
    "    #tifffile.imshow(core_img)\n",
    "    DFCI_piece_together[y1:y2, x1:x2] = core_img\n",
    "\n",
    "for i in Rochester_core_position['Core']:\n",
    "    x1 = Rochester_core_position[Rochester_core_position['Core'] == i]['x2_rotate'].values[0]\n",
    "    x2 = Rochester_core_position[Rochester_core_position['Core'] == i]['x1_rotate'].values[0]\n",
    "    y1 = Rochester_core_position[Rochester_core_position['Core'] == i]['y2_rotate'].values[0]\n",
    "    y2 = Rochester_core_position[Rochester_core_position['Core'] == i]['y1_rotate'].values[0]\n",
    "    core_img = Rochester_rotate[0][y1:y2, x1:x2]\n",
    "    #tifffile.imshow(core_img)\n",
    "    Rochester_piece_together[y1:y2, x1:x2] = core_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,12))\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.imshow(DFCI_rotate[0], cmap = 'gray')\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.imshow(Rochester_rotate[0], cmap = 'gray')\n",
    "ax3 = fig.add_subplot(2,2,3)\n",
    "ax3.imshow(DFCI_piece_together, cmap = 'gray')\n",
    "ax4 = fig.add_subplot(2,2,4)\n",
    "ax4.imshow(Rochester_piece_together, cmap = 'gray')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check json\n",
    "\n",
    "Check the configuration json files which contains the lower bound for each marker in each core. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/DFCI_config.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "for key, core_dict in data['cores'].items():\n",
    "    core_name = core_dict['core_name']\n",
    "    print(core_name)\n",
    "    print(DFCI_core_position[DFCI_core_position['Core'] == core_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the TMA based on user specified channel and threshold and segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing by setting all signal less than or equal to the lower bound to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rochester_core_dict = {}\n",
    "for i in Rochester_core_position['Core']:\n",
    "    x1 = Rochester_core_position[Rochester_core_position['Core'] == i]['x2_rotate'].values[0]\n",
    "    x2 = Rochester_core_position[Rochester_core_position['Core'] == i]['x1_rotate'].values[0]\n",
    "    y1 = Rochester_core_position[Rochester_core_position['Core'] == i]['y2_rotate'].values[0]\n",
    "    y2 = Rochester_core_position[Rochester_core_position['Core'] == i]['y1_rotate'].values[0]\n",
    "    core_img = Rochester_rotate[:, y1:y2, x1:x2]\n",
    "    print(f\"Processing core {i}\")\n",
    "    img_dict = process_fusion_image(core_img, '../data/MarkerList.txt', '../data/Rochester_config.json', coreName= i)\n",
    "    Rochester_core_dict[i] = img_dict\n",
    "    \n",
    "DFCI_core_dict = {}\n",
    "for i in DFCI_core_position['Core']:\n",
    "    x1 = DFCI_core_position[DFCI_core_position['Core'] == i]['x2_rotate'].values[0]\n",
    "    x2 = DFCI_core_position[DFCI_core_position['Core'] == i]['x1_rotate'].values[0]\n",
    "    y1 = DFCI_core_position[DFCI_core_position['Core'] == i]['y2_rotate'].values[0]\n",
    "    y2 = DFCI_core_position[DFCI_core_position['Core'] == i]['y1_rotate'].values[0]\n",
    "    core_img = DFCI_rotate[:, y1:y2, x1:x2]\n",
    "    print(f\"Processing core {i}\")\n",
    "    img_dict = process_fusion_image(core_img, '../data/MarkerList.txt', '../data/DFCI_config.json', coreName= i)\n",
    "    DFCI_core_dict[i] = img_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segment the cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Rochester_core_position['Core']:\n",
    "    img_dict = Rochester_core_dict[i]\n",
    "    segment_image(img_dict, ['DAPI'], ['HLA1', 'HLA-DR', 'CD31'], 0.5, f\"../output/seg_results/Rochester/core_{i}/\", maxima_threshold=0.075, interior_threshold=0.05, search_mode=False, run_mode=True)\n",
    "    \n",
    "for i in DFCI_core_position['Core']:\n",
    "    img_dict = DFCI_core_dict[i]\n",
    "    segment_image(img_dict, ['DAPI'], ['HLA1', 'HLA-DR', 'CD31'], 0.5, f\"../output/seg_results/DFCI/core_{i}/\", maxima_threshold=0.075, interior_threshold=0.05, search_mode=False, run_mode=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put the segmentation mask back for QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_canvas = np.zeros((Rochester_rotate[0].shape[0], Rochester_rotate[0].shape[1]), 'uint')\n",
    "\n",
    "\n",
    "for i in Rochester_core_position['Core']:\n",
    "    x1 = Rochester_core_position[Rochester_core_position['Core'] == i]['x2_rotate'].values[0]\n",
    "    x2 = Rochester_core_position[Rochester_core_position['Core'] == i]['x1_rotate'].values[0]\n",
    "    y1 = Rochester_core_position[Rochester_core_position['Core'] == i]['y2_rotate'].values[0]\n",
    "    y2 = Rochester_core_position[Rochester_core_position['Core'] == i]['y1_rotate'].values[0]\n",
    "    core_seg = tifffile.imread(f'../output/seg_results/Rochester/core_{i}/MESMER_mask.tiff')\n",
    "    #tifffile.imshow(core_img)\n",
    "    empty_canvas[y1:y2, x1:x2] = core_seg\n",
    "\n",
    "\n",
    "tifffile.imwrite('../data/Rochester_MESMER_mask.tiff', empty_canvas, photometric='minisblack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,12))\n",
    "ax4 = fig.add_subplot(1,4,1)\n",
    "ax4.imshow(Rochester_scan[0], cmap = 'gray')\n",
    "ax4.title.set_text('DAPI')\n",
    "ax1 = fig.add_subplot(1,4,2)\n",
    "ax1.imshow(Rochester_rotate[0], cmap = 'gray')\n",
    "ax1.title.set_text('DAPI rotated')\n",
    "ax2 = fig.add_subplot(1,4,3)\n",
    "ax2.imshow(Rochester_piece_together, cmap = 'gray')\n",
    "ax2.title.set_text('Cores pieced together')\n",
    "ax3 = fig.add_subplot(1,4,4)\n",
    "ax3.imshow(empty_canvas, cmap = 'gray')\n",
    "ax3.title.set_text('Segmentation pieced together')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_canvas = np.zeros((DFCI_rotate[0].shape[0], DFCI_rotate[0].shape[1]), 'uint')\n",
    "\n",
    "\n",
    "for i in DFCI_core_position['Core']:\n",
    "    x1 = DFCI_core_position[DFCI_core_position['Core'] == i]['x2_rotate'].values[0]\n",
    "    x2 = DFCI_core_position[DFCI_core_position['Core'] == i]['x1_rotate'].values[0]\n",
    "    y1 = DFCI_core_position[DFCI_core_position['Core'] == i]['y2_rotate'].values[0]\n",
    "    y2 = DFCI_core_position[DFCI_core_position['Core'] == i]['y1_rotate'].values[0]\n",
    "    core_seg = tifffile.imread(f'../output/seg_results/DFCI/core_{i}/MESMER_mask.tiff')\n",
    "    #tifffile.imshow(core_img)\n",
    "    empty_canvas[y1:y2, x1:x2] = core_seg\n",
    "\n",
    "\n",
    "tifffile.imwrite('../data/DFCI_MESMER_mask.tiff', empty_canvas, photometric='minisblack')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,12))\n",
    "ax4 = fig.add_subplot(1,4,1)\n",
    "ax4.imshow(DFCI_scan[0], cmap = 'gray')\n",
    "ax4.title.set_text('DAPI')\n",
    "ax1 = fig.add_subplot(1,4,2)\n",
    "ax1.imshow(DFCI_rotate[0], cmap = 'gray')\n",
    "ax1.title.set_text('DAPI rotated')\n",
    "ax2 = fig.add_subplot(1,4,3)\n",
    "ax2.imshow(DFCI_piece_together, cmap = 'gray')\n",
    "ax2.title.set_text('Cores pieced together')\n",
    "ax3 = fig.add_subplot(1,4,4)\n",
    "ax3.imshow(empty_canvas, cmap = 'gray')\n",
    "ax3.title.set_text('Segmentation pieced together')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract single cell information from Fusion scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read marker list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = open('../data/MarkerList.txt', 'r')\n",
    "\n",
    "clusterChannels = txt_file.read().split('\\n')\n",
    "\n",
    "txt_file.close()\n",
    "\n",
    "print(clusterChannels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract from TMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract single cell information with the segmentation mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for core in Rochester_core_position['Core']:\n",
    "    array_list = []\n",
    "    core_img = Rochester_core_dict[core]\n",
    "    channelNum = len(core_img)\n",
    "    for channel in clusterChannels:\n",
    "        m = core_img[channel]\n",
    "        array_list.append(m)\n",
    "    countsNoNoise=np.stack(array_list, axis=2) # count matrices in the image\n",
    "\n",
    "    # load mask\n",
    "    segMat = skimage.io.imread(f\"../output/seg_results/Rochester/core_{core}/MESMER_mask.tiff\")\n",
    "    stats = skimage.measure.regionprops(segMat)\n",
    "    labelNum = len(stats) # number of actual cells not always equal to np.max(segMat)\n",
    "\n",
    "    # init empty containers\n",
    "    data = np.zeros((labelNum,channelNum))\n",
    "    dataScaleSize = np.zeros((labelNum,channelNum))\n",
    "    cellSizes = np.zeros((labelNum,1))\n",
    "    cell_props = np.zeros((labelNum, 3))\n",
    "\n",
    "    # extract info\n",
    "    for i in range(labelNum): # for each cell (label)\n",
    "        cellLabel = stats[i].label\n",
    "        label_counts=[countsNoNoise[coord[0],coord[1],:] for coord in stats[i].coords] # all channel count for this cell\n",
    "        data[i, 0:channelNum] = np.sum(label_counts, axis=0) #  sum the counts for this cell\n",
    "        dataScaleSize[i,0:channelNum] = np.sum(label_counts, axis=0) / stats[i].area # scaled by size\n",
    "        cellSizes[i] = stats[i].area # cell sizes\n",
    "        cell_props[i, 0] = cellLabel\n",
    "        cell_props[i, 1] = stats[i].centroid[0] # Y_cent\n",
    "        cell_props[i, 2] = stats[i].centroid[1] # X_cent\n",
    "\n",
    "    data_df = pd.DataFrame(data)\n",
    "    data_df.columns = clusterChannels\n",
    "    data_full = pd.concat((pd.DataFrame(cell_props, columns = [\"cellLabel\", \"Y_cent\", \"X_cent\"]), pd.DataFrame(cellSizes, columns = [\"cellSize\"]), data_df), axis=1)\n",
    "\n",
    "    dataScaleSize_df = pd.DataFrame(dataScaleSize)\n",
    "    dataScaleSize_df.columns = clusterChannels\n",
    "    dataScaleSize_full = pd.concat((pd.DataFrame(cell_props, columns = [\"cellLabel\", \"Y_cent\", \"X_cent\"]), pd.DataFrame(cellSizes, columns = [\"cellSize\"]), dataScaleSize_df), axis = 1)\n",
    "\n",
    "    # save all dfs\n",
    "    save_dir = f'../output/extracted_info_052024/Rochester/core_{core}'\n",
    "\n",
    "    if os.path.exists(save_dir) == False:\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    data_full.to_csv(save_dir + \"/data.csv\", index = False)\n",
    "    dataScaleSize_full.to_csv(save_dir + \"/dataScaleSize.csv\", index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for core in DFCI_core_position['Core']:\n",
    "    array_list = []\n",
    "    core_img = DFCI_core_dict[core]\n",
    "    channelNum = len(core_img)\n",
    "    for channel in clusterChannels:\n",
    "        m = core_img[channel]\n",
    "        array_list.append(m)\n",
    "    countsNoNoise=np.stack(array_list, axis=2) # count matrices in the image\n",
    "\n",
    "    # load mask\n",
    "    segMat = skimage.io.imread(f\"../output/seg_results/DFCI/core_{core}/MESMER_mask.tiff\")\n",
    "    stats = skimage.measure.regionprops(segMat)\n",
    "    labelNum = len(stats) # number of actual cells not always equal to np.max(segMat)\n",
    "\n",
    "    # init empty containers\n",
    "    data = np.zeros((labelNum,channelNum))\n",
    "    dataScaleSize = np.zeros((labelNum,channelNum))\n",
    "    cellSizes = np.zeros((labelNum,1))\n",
    "    cell_props = np.zeros((labelNum, 3))\n",
    "\n",
    "    # extract info\n",
    "    for i in range(labelNum): # for each cell (label)\n",
    "        cellLabel = stats[i].label\n",
    "        label_counts=[countsNoNoise[coord[0],coord[1],:] for coord in stats[i].coords] # all channel count for this cell\n",
    "        data[i, 0:channelNum] = np.sum(label_counts, axis=0) #  sum the counts for this cell\n",
    "        dataScaleSize[i,0:channelNum] = np.sum(label_counts, axis=0) / stats[i].area # scaled by size\n",
    "        cellSizes[i] = stats[i].area # cell sizes\n",
    "        cell_props[i, 0] = cellLabel\n",
    "        cell_props[i, 1] = stats[i].centroid[0] # Y_cent\n",
    "        cell_props[i, 2] = stats[i].centroid[1] # X_cent\n",
    "\n",
    "    data_df = pd.DataFrame(data)\n",
    "    data_df.columns = clusterChannels\n",
    "    data_full = pd.concat((pd.DataFrame(cell_props, columns = [\"cellLabel\", \"Y_cent\", \"X_cent\"]), pd.DataFrame(cellSizes, columns = [\"cellSize\"]), data_df), axis=1)\n",
    "\n",
    "    dataScaleSize_df = pd.DataFrame(dataScaleSize)\n",
    "    dataScaleSize_df.columns = clusterChannels\n",
    "    dataScaleSize_full = pd.concat((pd.DataFrame(cell_props, columns = [\"cellLabel\", \"Y_cent\", \"X_cent\"]), pd.DataFrame(cellSizes, columns = [\"cellSize\"]), dataScaleSize_df), axis = 1)\n",
    "\n",
    "    # save all dfs\n",
    "    save_dir = f'../output/extracted_info_052024/DFCI/core_{core}'\n",
    "\n",
    "    if os.path.exists(save_dir) == False:\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    data_full.to_csv(save_dir + \"/data.csv\", index = False)\n",
    "    dataScaleSize_full.to_csv(save_dir + \"/dataScaleSize.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare image for mantis-viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for i in Rochester_core_position['Core']:\n",
    "    seg = f\"../output/seg_results/Rochester/core_{i}/MESMER_mask.tiff\"\n",
    "    outpath = f\"../output/core_img/Rochester/core_{i}/\"\n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "    shutil.copy2(seg, f\"{outpath}MESMER_mask.tiff\")\n",
    "    for j in clusterChannels:\n",
    "        img = Rochester_core_dict[i][j]\n",
    "        tifffile.imwrite(f\"../output/core_img/Rochester/core_{i}/{j}.tiff\", img, photometric = 'minisblack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for i in DFCI_core_position['Core']:\n",
    "    seg = f\"../output/seg_results/DFCI/core_{i}/MESMER_mask.tiff\"\n",
    "    outpath = f\"../output/core_img/DFCI/core_{i}/\"\n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "    shutil.copy2(seg, f\"{outpath}MESMER_mask.tiff\")\n",
    "    for j in clusterChannels:\n",
    "        img = DFCI_core_dict[i][j]\n",
    "        tifffile.imwrite(f\"../output/core_img/DFCI/core_{i}/{j}.tiff\", img, photometric='minisblack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional processing for BCL2 and BCL6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the staining for BCL2 and BLC6 in the initial scan didn't have good quality. A rescan was performed to rescue the markers. Therefore, an additional round of single cell information extraction was performed to extract BCL2 and BCL6 from the rescan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFCI_BCL2 = tifffile.imread('../output/img_registration/fusion_to_fusion/DFCI_BCL2.tiff')\n",
    "DFCI_BCL6 = tifffile.imread('../output/img_registration/fusion_to_fusion/DFCI_BCL6.tiff')\n",
    "\n",
    "Rochester_BCL2 = tifffile.imread('../output/img_registration/fusion_to_fusion/Rochester_BCL2.tiff')\n",
    "Rochester_BCL6 = tifffile.imread('../output/img_registration/fusion_to_fusion/Rochester_BCL6.tiff')\n",
    "\n",
    "DFCI_BCL = np.stack((DFCI_BCL2, DFCI_BCL6))\n",
    "\n",
    "Rochester_BCL = np.stack((Rochester_BCL2, Rochester_BCL6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.imshow(DFCI_BCL[0], cmap='gray')\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.imshow(DFCI_BCL[1], cmap = 'gray')\n",
    "ax3 = fig.add_subplot(2,2,3)\n",
    "ax3.imshow(Rochester_BCL[0], cmap = 'gray')\n",
    "ax4 = fig.add_subplot(2,2,4)\n",
    "ax4.imshow(Rochester_BCL[1], cmap = 'gray')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rochester_BCL_dict = {}\n",
    "for i in Rochester_core_position['Core']:\n",
    "    x1 = Rochester_core_position[Rochester_core_position['Core'] == i]['x2_rotate'].values[0]\n",
    "    x2 = Rochester_core_position[Rochester_core_position['Core'] == i]['x1_rotate'].values[0]\n",
    "    y1 = Rochester_core_position[Rochester_core_position['Core'] == i]['y2_rotate'].values[0]\n",
    "    y2 = Rochester_core_position[Rochester_core_position['Core'] == i]['y1_rotate'].values[0]\n",
    "    core_img = Rochester_BCL[:, y1:y2, x1:x2]\n",
    "    print(f\"Processing core {i}\")\n",
    "    img_dict = process_fusion_image(core_img, '../data/MarkerList_2.txt', '../data/Rochester_config_BCL.json', coreName= i)\n",
    "    Rochester_BCL_dict[i] = img_dict\n",
    "\n",
    "DFCI_BCL_dict = {}\n",
    "for i in DFCI_core_position['Core']:\n",
    "    x1 = DFCI_core_position[DFCI_core_position['Core'] == i]['x2_rotate'].values[0]\n",
    "    x2 = DFCI_core_position[DFCI_core_position['Core'] == i]['x1_rotate'].values[0]\n",
    "    y1 = DFCI_core_position[DFCI_core_position['Core'] == i]['y2_rotate'].values[0]\n",
    "    y2 = DFCI_core_position[DFCI_core_position['Core'] == i]['y1_rotate'].values[0]\n",
    "    core_img = DFCI_BCL[:, y1:y2, x1:x2]\n",
    "    print(f\"Processing core {i}\")\n",
    "    img_dict = process_fusion_image(core_img, '../data/MarkerList_2.txt', '../data/DFCI_config_BCL.json', coreName= i)\n",
    "    DFCI_BCL_dict[i] = img_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = open('../data/MarkerList_2.txt', 'r')\n",
    "\n",
    "clusterChannels = txt_file.read().split('\\n')\n",
    "\n",
    "txt_file.close()\n",
    "\n",
    "print(clusterChannels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract single cell information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for core in Rochester_core_position['Core']:\n",
    "    array_list = []\n",
    "    core_img = Rochester_BCL_dict[core]\n",
    "    channelNum = len(core_img)\n",
    "    for channel in clusterChannels:\n",
    "        m = core_img[channel]\n",
    "        array_list.append(m)\n",
    "    countsNoNoise=np.stack(array_list, axis=2) # count matrices in the image\n",
    "\n",
    "    # load mask\n",
    "    segMat = skimage.io.imread(f\"../output/seg_results/Rochester/core_{core}/MESMER_mask.tiff\")\n",
    "    stats = skimage.measure.regionprops(segMat)\n",
    "    labelNum = len(stats) # number of actual cells not always equal to np.max(segMat)\n",
    "\n",
    "    # init empty containers\n",
    "    data = np.zeros((labelNum,channelNum))\n",
    "    dataScaleSize = np.zeros((labelNum,channelNum))\n",
    "    cellSizes = np.zeros((labelNum,1))\n",
    "    cell_props = np.zeros((labelNum, 3))\n",
    "\n",
    "    # extract info\n",
    "    for i in range(labelNum): # for each cell (label)\n",
    "        cellLabel = stats[i].label\n",
    "        label_counts=[countsNoNoise[coord[0],coord[1],:] for coord in stats[i].coords] # all channel count for this cell\n",
    "        data[i, 0:channelNum] = np.sum(label_counts, axis=0) #  sum the counts for this cell\n",
    "        dataScaleSize[i,0:channelNum] = np.sum(label_counts, axis=0) / stats[i].area # scaled by size\n",
    "        cellSizes[i] = stats[i].area # cell sizes\n",
    "        cell_props[i, 0] = cellLabel\n",
    "        cell_props[i, 1] = stats[i].centroid[0] # Y_cent\n",
    "        cell_props[i, 2] = stats[i].centroid[1] # X_cent\n",
    "\n",
    "    data_df = pd.DataFrame(data)\n",
    "    data_df.columns = clusterChannels\n",
    "    data_full = pd.concat((pd.DataFrame(cell_props, columns = [\"cellLabel\", \"Y_cent\", \"X_cent\"]), pd.DataFrame(cellSizes, columns = [\"cellSize\"]), data_df), axis=1)\n",
    "\n",
    "    dataScaleSize_df = pd.DataFrame(dataScaleSize)\n",
    "    dataScaleSize_df.columns = clusterChannels\n",
    "    dataScaleSize_full = pd.concat((pd.DataFrame(cell_props, columns = [\"cellLabel\", \"Y_cent\", \"X_cent\"]), pd.DataFrame(cellSizes, columns = [\"cellSize\"]), dataScaleSize_df), axis = 1)\n",
    "\n",
    "    # save all dfs\n",
    "    save_dir = f'../output/extracted_info/Rochester_BCL/core_{core}'\n",
    "\n",
    "    if os.path.exists(save_dir) == False:\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    data_full.to_csv(save_dir + \"/data.csv\", index = False)\n",
    "    dataScaleSize_full.to_csv(save_dir + \"/dataScaleSize.csv\", index = False)\n",
    "    \n",
    "for core in DFCI_core_position['Core']:\n",
    "    array_list = []\n",
    "    core_img = DFCI_BCL_dict[core]\n",
    "    channelNum = len(core_img)\n",
    "    for channel in clusterChannels:\n",
    "        m = core_img[channel]\n",
    "        array_list.append(m)\n",
    "    countsNoNoise=np.stack(array_list, axis=2) # count matrices in the image\n",
    "\n",
    "    # load mask\n",
    "    segMat = skimage.io.imread(f\"../output/seg_results/DFCI/core_{core}/MESMER_mask.tiff\")\n",
    "    stats = skimage.measure.regionprops(segMat)\n",
    "    labelNum = len(stats) # number of actual cells not always equal to np.max(segMat)\n",
    "\n",
    "    # init empty containers\n",
    "    data = np.zeros((labelNum,channelNum))\n",
    "    dataScaleSize = np.zeros((labelNum,channelNum))\n",
    "    cellSizes = np.zeros((labelNum,1))\n",
    "    cell_props = np.zeros((labelNum, 3))\n",
    "\n",
    "    # extract info\n",
    "    for i in range(labelNum): # for each cell (label)\n",
    "        cellLabel = stats[i].label\n",
    "        label_counts=[countsNoNoise[coord[0],coord[1],:] for coord in stats[i].coords] # all channel count for this cell\n",
    "        data[i, 0:channelNum] = np.sum(label_counts, axis=0) #  sum the counts for this cell\n",
    "        dataScaleSize[i,0:channelNum] = np.sum(label_counts, axis=0) / stats[i].area # scaled by size\n",
    "        cellSizes[i] = stats[i].area # cell sizes\n",
    "        cell_props[i, 0] = cellLabel\n",
    "        cell_props[i, 1] = stats[i].centroid[0] # Y_cent\n",
    "        cell_props[i, 2] = stats[i].centroid[1] # X_cent\n",
    "\n",
    "    data_df = pd.DataFrame(data)\n",
    "    data_df.columns = clusterChannels\n",
    "    data_full = pd.concat((pd.DataFrame(cell_props, columns = [\"cellLabel\", \"Y_cent\", \"X_cent\"]), pd.DataFrame(cellSizes, columns = [\"cellSize\"]), data_df), axis=1)\n",
    "\n",
    "    dataScaleSize_df = pd.DataFrame(dataScaleSize)\n",
    "    dataScaleSize_df.columns = clusterChannels\n",
    "    dataScaleSize_full = pd.concat((pd.DataFrame(cell_props, columns = [\"cellLabel\", \"Y_cent\", \"X_cent\"]), pd.DataFrame(cellSizes, columns = [\"cellSize\"]), dataScaleSize_df), axis = 1)\n",
    "\n",
    "    # save all dfs\n",
    "    save_dir = f'../output/extracted_info/DFCI_BCL/core_{core}'\n",
    "\n",
    "    if os.path.exists(save_dir) == False:\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    data_full.to_csv(save_dir + \"/data.csv\", index = False)\n",
    "    dataScaleSize_full.to_csv(save_dir + \"/dataScaleSize.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional processing for Myc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Myc was used for subtyping tumors. Therefore, a lower bound was also applied to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFCI_geomx = tifffile.imread('../data/DFCI_geomx.ome.tiff')\n",
    "DFCI_geomx_position = pd.read_csv('../data/DFCI_geomx_position.csv')\n",
    "txt_file = open('../data/MarkerList_3.txt', 'r')\n",
    "\n",
    "clusterChannels = txt_file.read().split('\\n')\n",
    "\n",
    "txt_file.close()\n",
    "\n",
    "print(clusterChannels)\n",
    "DFCI_myc_dict = {}\n",
    "for i in DFCI_geomx_position['Core']:\n",
    "    x1 = DFCI_geomx_position[DFCI_geomx_position['Core'] == i]['x1'].values[0]\n",
    "    x2 = DFCI_geomx_position[DFCI_geomx_position['Core'] == i]['x2'].values[0]\n",
    "    y1 = DFCI_geomx_position[DFCI_geomx_position['Core'] == i]['y1'].values[0]\n",
    "    y2 = DFCI_geomx_position[DFCI_geomx_position['Core'] == i]['y2'].values[0]\n",
    "    core_img = DFCI_geomx[:, y1:y2, x1:x2]\n",
    "    print(f\"Processing core {i}\")\n",
    "    img_dict = process_fusion_image(core_img, '../data/MarkerList_3.txt', '../data/DFCI_config_myc.json', coreName= i)\n",
    "    DFCI_myc_dict[i] = img_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load segmentation masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFCI_aligned_MESMER_mask = tifffile.imread('../output/img_registration/fusion_to_geomx/DFCI_aligned_MESMER_mask.tiff').astype('uint32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(DFCI_geomx_position['Core']):\n",
    "    x1 = DFCI_geomx_position[DFCI_geomx_position['Core'] == i]['x1'].values[0]\n",
    "    x2 = DFCI_geomx_position[DFCI_geomx_position['Core'] == i]['x2'].values[0]\n",
    "    y1 = DFCI_geomx_position[DFCI_geomx_position['Core'] == i]['y1'].values[0]\n",
    "    y2 = DFCI_geomx_position[DFCI_geomx_position['Core'] == i]['y2'].values[0]\n",
    "    core_seg = DFCI_aligned_MESMER_mask[y1:y2,x1:x2]\n",
    "    output_path = f\"../output/seg_results/DFCI_geomx/core_{i}\"\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    tifffile.imwrite(f\"{output_path}/MESMER_mask.tiff\", core_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = open('../data/MarkerList_3.txt', 'r')\n",
    "\n",
    "clusterChannels = txt_file.read().split('\\n')\n",
    "\n",
    "txt_file.close()\n",
    "\n",
    "print(clusterChannels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract single cell information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for core in DFCI_geomx_position['Core']:\n",
    "    array_list = []\n",
    "    core_img = DFCI_myc_dict[core]\n",
    "    channelNum = len(core_img)\n",
    "    for channel in clusterChannels:\n",
    "        m = core_img[channel]\n",
    "        array_list.append(m)\n",
    "    countsNoNoise=np.stack(array_list, axis=2) # count matrices in the image\n",
    "\n",
    "    # load mask\n",
    "    segMat = skimage.io.imread(f\"../output/seg_results/DFCI_geomx/core_{core}/MESMER_mask.tiff\")\n",
    "    stats = skimage.measure.regionprops(segMat)\n",
    "    labelNum = len(stats) # number of actual cells not always equal to np.max(segMat)\n",
    "\n",
    "    # init empty containers\n",
    "    data = np.zeros((labelNum,channelNum))\n",
    "    dataScaleSize = np.zeros((labelNum,channelNum))\n",
    "    cellSizes = np.zeros((labelNum,1))\n",
    "    cell_props = np.zeros((labelNum, 3))\n",
    "\n",
    "    # extract info\n",
    "    for i in range(labelNum): # for each cell (label)\n",
    "        cellLabel = stats[i].label\n",
    "        label_counts=[countsNoNoise[coord[0],coord[1],:] for coord in stats[i].coords] # all channel count for this cell\n",
    "        data[i, 0:channelNum] = np.sum(label_counts, axis=0) #  sum the counts for this cell\n",
    "        dataScaleSize[i,0:channelNum] = np.sum(label_counts, axis=0) / stats[i].area # scaled by size\n",
    "        cellSizes[i] = stats[i].area # cell sizes\n",
    "        cell_props[i, 0] = cellLabel\n",
    "        cell_props[i, 1] = stats[i].centroid[0] # Y_cent\n",
    "        cell_props[i, 2] = stats[i].centroid[1] # X_cent\n",
    "\n",
    "    data_df = pd.DataFrame(data)\n",
    "    data_df.columns = clusterChannels\n",
    "    data_full = pd.concat((pd.DataFrame(cell_props, columns = [\"cellLabel\", \"Y_cent\", \"X_cent\"]), pd.DataFrame(cellSizes, columns = [\"cellSize\"]), data_df), axis=1)\n",
    "\n",
    "    dataScaleSize_df = pd.DataFrame(dataScaleSize)\n",
    "    dataScaleSize_df.columns = clusterChannels\n",
    "    dataScaleSize_full = pd.concat((pd.DataFrame(cell_props, columns = [\"cellLabel\", \"Y_cent\", \"X_cent\"]), pd.DataFrame(cellSizes, columns = [\"cellSize\"]), dataScaleSize_df), axis = 1)\n",
    "\n",
    "    # save all dfs\n",
    "    save_dir = f'../output/extracted_info_052024/DFCI_geomx/core_{core}'\n",
    "\n",
    "    if os.path.exists(save_dir) == False:\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    data_full.to_csv(save_dir + \"/data.csv\", index = False)\n",
    "    dataScaleSize_full.to_csv(save_dir + \"/dataScaleSize.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rochester_geomx = tifffile.imread('../data/Rochester_geomx.ome.tiff')\n",
    "Rochester_geomx_position = pd.read_csv('../data/Rochester_geomx_position.csv')\n",
    "Rochester_geomx_position\n",
    "txt_file = open('../data/MarkerList_3.txt', 'r')\n",
    "\n",
    "clusterChannels = txt_file.read().split('\\n')\n",
    "\n",
    "txt_file.close()\n",
    "\n",
    "print(clusterChannels)\n",
    "Rochester_myc_dict = {}\n",
    "for i in Rochester_geomx_position['Core']:\n",
    "    x1 = Rochester_geomx_position[Rochester_geomx_position['Core'] == i]['x1'].values[0]\n",
    "    x2 = Rochester_geomx_position[Rochester_geomx_position['Core'] == i]['x2'].values[0]\n",
    "    y1 = Rochester_geomx_position[Rochester_geomx_position['Core'] == i]['y1'].values[0]\n",
    "    y2 = Rochester_geomx_position[Rochester_geomx_position['Core'] == i]['y2'].values[0]\n",
    "    core_img = Rochester_geomx[:, y1:y2, x1:x2]\n",
    "    print(f\"Processing core {i}\")\n",
    "    img_dict = process_fusion_image(core_img, '../data/MarkerList_3.txt', '../data/Rochester_config_myc.json', coreName= i)\n",
    "    Rochester_myc_dict[i] = img_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract single cell information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for core in tqdm(Rochester_geomx_position['Core']):\n",
    "    array_list = []\n",
    "    core_img = Rochester_myc_dict[core]\n",
    "    channelNum = len(core_img)\n",
    "    for channel in clusterChannels:\n",
    "        m = core_img[channel]\n",
    "        array_list.append(m)\n",
    "    countsNoNoise=np.stack(array_list, axis=2) # count matrices in the image\n",
    "\n",
    "    # load mask\n",
    "    segMat = skimage.io.imread(f\"../output/img_registration/fusion_to_geomx/Rochester/Rochester_{core}/Rochester_aligned_MESMER_mask.tiff\").astype('uint32')\n",
    "    stats = skimage.measure.regionprops(segMat)\n",
    "    labelNum = len(stats) # number of actual cells not always equal to np.max(segMat)\n",
    "\n",
    "    # init empty containers\n",
    "    data = np.zeros((labelNum,channelNum))\n",
    "    dataScaleSize = np.zeros((labelNum,channelNum))\n",
    "    cellSizes = np.zeros((labelNum,1))\n",
    "    cell_props = np.zeros((labelNum, 3))\n",
    "\n",
    "    # extract info\n",
    "    for i in range(labelNum): # for each cell (label)\n",
    "        cellLabel = stats[i].label\n",
    "        label_counts=[countsNoNoise[coord[0],coord[1],:] for coord in stats[i].coords] # all channel count for this cell\n",
    "        data[i, 0:channelNum] = np.sum(label_counts, axis=0) #  sum the counts for this cell\n",
    "        dataScaleSize[i,0:channelNum] = np.sum(label_counts, axis=0) / stats[i].area # scaled by size\n",
    "        cellSizes[i] = stats[i].area # cell sizes\n",
    "        cell_props[i, 0] = cellLabel\n",
    "        cell_props[i, 1] = stats[i].centroid[0] # Y_cent\n",
    "        cell_props[i, 2] = stats[i].centroid[1] # X_cent\n",
    "\n",
    "    data_df = pd.DataFrame(data)\n",
    "    data_df.columns = clusterChannels\n",
    "    data_full = pd.concat((pd.DataFrame(cell_props, columns = [\"cellLabel\", \"Y_cent\", \"X_cent\"]), pd.DataFrame(cellSizes, columns = [\"cellSize\"]), data_df), axis=1)\n",
    "\n",
    "    dataScaleSize_df = pd.DataFrame(dataScaleSize)\n",
    "    dataScaleSize_df.columns = clusterChannels\n",
    "    dataScaleSize_full = pd.concat((pd.DataFrame(cell_props, columns = [\"cellLabel\", \"Y_cent\", \"X_cent\"]), pd.DataFrame(cellSizes, columns = [\"cellSize\"]), dataScaleSize_df), axis = 1)\n",
    "\n",
    "    # save all dfs\n",
    "    save_dir = f'../output/extracted_info_052024/Rochester_geomx/core_{core}'\n",
    "\n",
    "    if os.path.exists(save_dir) == False:\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    data_full.to_csv(save_dir + \"/data.csv\", index = False)\n",
    "    dataScaleSize_full.to_csv(save_dir + \"/dataScaleSize.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellSeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
